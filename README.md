# GestureRecognition

Imagine you are working as a data scientist at a home electronics company which manufactures state of the art smart televisions. You want to develop a cool feature in the smart-TV that can recognise five different gestures performed by the user which will help users control the TV without using a remote.
The gestures are continuously monitored by the webcam mounted on the TV. 

Each gesture corresponds to a specific command:

1. Thumbs up:  Increase the volume
2. Thumbs down: Decrease the volume
3. Left swipe: 'Jump' backwards 10 seconds
4. Right swipe: 'Jump' forward 10 seconds  
5. Stop: Pause the movie

# Filesets

1. Gesture Recognition.ipynb
2. Model Experiments and Observations Summary
3. Readme.md
4. Best Models Saved under models ( Capturing val and train accuracies)

# Architectures Used

1. Conv3d
2. Conv2d + LSTM
3. Conv2d + GRU
4. Conv2d + Bidirectional LSTM
5. Conv2d + Bidirectional GRU
6. Conv2d + Bidirectional Stacked GRU
7. Transfer Learning - Mobile Net
8. Transfer Learning - ResNet50

# Tech Stack : 
python,seaborne,keras,tensorflow
